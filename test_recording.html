<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Recording Test</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 40px; }
        .container { max-width: 800px; margin: 0 auto; }
        .recording-section { border: 2px solid #007bff; border-radius: 8px; padding: 20px; margin: 20px 0; }
        .record-btn { 
            background: #007bff; 
            color: white; 
            border: none; 
            padding: 15px 30px; 
            border-radius: 5px; 
            font-size: 16px; 
            cursor: pointer; 
            margin: 10px;
        }
        .record-btn:hover { background: #0056b3; }
        .record-btn.recording { background: #dc3545; }
        .record-btn.processing { background: #ffc107; color: #000; }
        .status { margin: 10px 0; font-weight: bold; }
        .logs { background: #f8f9fa; padding: 15px; border-radius: 5px; margin-top: 20px; }
        .timer { font-family: monospace; font-size: 18px; margin: 10px 0; }
    </style>
</head>
<body>
    <div class="container">
        <h1>üé§ Voice Recording Test</h1>
        <p>This page tests the voice recording functionality and logging.</p>
        
        <div class="recording-section">
            <h3>AI Voice Transcription</h3>
            
            <button id="aiTranscriptionBtn" class="record-btn">
                <span id="aiMicIcon">üé§</span>
                <span id="aiBtnText">Start Recording</span>
            </button>
            
            <div id="recordingTimer" class="timer" style="display: none;">
                Recording: <span id="timerDisplay">00:00</span>
            </div>
            
            <div id="aiStatus" class="status">Ready to record</div>
            
            <div id="transcriptionResult" style="display: none;">
                <h4>Transcription Result:</h4>
                <div id="transcriptionText" style="background: #e9ecef; padding: 10px; border-radius: 3px;"></div>
            </div>
        </div>
        
        <div class="logs">
            <h4>Console Logs:</h4>
            <div id="logOutput"></div>
        </div>
        
        <!-- Hidden CSRF token for testing -->
        <input type="hidden" name="csrf_token_form" value="test_token_123">
    </div>

    <script>
        // Voice Recording Variables
        let mediaRecorder;
        let audioChunks = [];
        let isRecording = false;
        let recordingStartTime;
        let timerInterval;
        
        // DOM Elements
        const aiBtn = document.getElementById('aiTranscriptionBtn');
        const aiStatus = document.getElementById('aiStatus');
        const aiBtnText = document.getElementById('aiBtnText');
        const aiMicIcon = document.getElementById('aiMicIcon');
        const recordingTimer = document.getElementById('recordingTimer');
        const timerDisplay = document.getElementById('timerDisplay');
        const transcriptionResult = document.getElementById('transcriptionResult');
        const transcriptionText = document.getElementById('transcriptionText');
        const logOutput = document.getElementById('logOutput');
        
        // Enhanced logging function
        function addLog(message) {
            console.log(message);
            const timestamp = new Date().toLocaleTimeString();
            logOutput.innerHTML += `[${timestamp}] ${message}<br>`;
            logOutput.scrollTop = logOutput.scrollHeight;
        }
        
        addLog('üî• Voice recording test page initialized');
        
        // Event Listeners
        aiBtn.addEventListener('click', async function() {
            addLog('üî• AI Transcription button clicked, isRecording: ' + isRecording);
            if (!isRecording) {
                await startRecording();
            } else {
                stopRecording();
            }
        });
        
        async function startRecording() {
            try {
                addLog('üî• Starting voice recording...');
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        sampleRate: 44100
                    } 
                });
                
                // Determine best audio format
                let mimeType = 'audio/wav';
                const supportedTypes = [
                    'audio/wav',
                    'audio/webm;codecs=opus',
                    'audio/webm',
                    'audio/mp4',
                    'audio/ogg;codecs=opus'
                ];
                
                for (const type of supportedTypes) {
                    if (MediaRecorder.isTypeSupported(type)) {
                        mimeType = type;
                        addLog('üî• Using MIME type: ' + mimeType);
                        break;
                    }
                }
                
                mediaRecorder = new MediaRecorder(stream, { mimeType: mimeType });
                audioChunks = [];
                
                mediaRecorder.ondataavailable = function(event) {
                    addLog('üî• Audio data available: ' + event.data.size + ' bytes');
                    audioChunks.push(event.data);
                };
                
                mediaRecorder.onstop = async function() {
                    addLog('üî• Recording stopped, processing audio...');
                    const audioBlob = new Blob(audioChunks, { type: mimeType });
                    addLog('üî• Audio blob created: ' + audioBlob.size + ' bytes, type: ' + audioBlob.type);
                    addLog('üî• About to call transcribeAudio...');
                    await transcribeAudio(audioBlob);
                    addLog('üî• transcribeAudio completed');
                    stream.getTracks().forEach(track => track.stop());
                };
                
                // Start recording
                mediaRecorder.start(1000);
                isRecording = true;
                recordingStartTime = Date.now();
                
                // Update UI for recording state
                aiBtn.className = 'record-btn recording';
                aiBtnText.textContent = 'Stop Recording';
                aiMicIcon.textContent = '‚èπÔ∏è';
                aiStatus.textContent = 'Recording in progress...';
                
                // Show and start timer
                recordingTimer.style.display = 'block';
                startRecordingTimer();
                
            } catch (error) {
                addLog('üî• Error accessing microphone: ' + error.message);
                aiStatus.textContent = 'Error: Could not access microphone';
                alert('Unable to access microphone. Please check your browser permissions and try again.');
            }
        }
        
        function stopRecording() {
            if (mediaRecorder && isRecording) {
                addLog('üî• Stopping recording...');
                mediaRecorder.stop();
                isRecording = false;
                
                // Stop timer
                if (timerInterval) {
                    clearInterval(timerInterval);
                }
                
                // Update UI for processing state
                aiBtn.className = 'record-btn processing';
                aiBtnText.textContent = 'Processing...';
                aiMicIcon.textContent = '‚è≥';
                aiStatus.textContent = 'Transcribing with OpenAI Whisper...';
                aiBtn.disabled = true;
            }
        }
        
        function startRecordingTimer() {
            timerInterval = setInterval(function() {
                if (recordingStartTime) {
                    const elapsed = Date.now() - recordingStartTime;
                    const minutes = Math.floor(elapsed / 60000);
                    const seconds = Math.floor((elapsed % 60000) / 1000);
                    timerDisplay.textContent = 
                        (minutes < 10 ? '0' : '') + minutes + ':' + 
                        (seconds < 10 ? '0' : '') + seconds;
                }
            }, 1000);
        }
        
        async function transcribeAudio(audioBlob) {
            const formData = new FormData();
            
            // Create filename with proper extension
            let filename = 'voice-recording.wav';
            if (audioBlob.type.includes('webm')) {
                filename = 'voice-recording.webm';
            } else if (audioBlob.type.includes('mp4')) {
                filename = 'voice-recording.m4a';
            } else if (audioBlob.type.includes('ogg')) {
                filename = 'voice-recording.ogg';
            }
            
            addLog('üî• Uploading audio file: ' + filename + ', Size: ' + audioBlob.size + ', Type: ' + audioBlob.type);
            
            formData.append('audio', audioBlob, filename);
            formData.append('csrf_token_form', document.querySelector('input[name="csrf_token_form"]').value);
            
            try {
                // Use our test endpoint
                const url = '/interface/forms/newpatient/whisper_test.php';
                addLog('üî• MAKING FETCH REQUEST TO: ' + url);
                addLog('üî• FormData contents: ' + Array.from(formData.entries()).map(([k,v]) => k + '=' + (v.size ? v.size + ' bytes' : v)).join(', '));
                
                const response = await fetch(url, {
                    method: 'POST',
                    body: formData
                });
                
                addLog('üî• Transcription response status: ' + response.status);
                
                if (!response.ok) {
                    const errorText = await response.text();
                    addLog('üî• Transcription server error: ' + errorText);
                    throw new Error(`Server error (${response.status}): ${errorText.substring(0, 100)}`);
                }
                
                const result = await response.json();
                addLog('üî• Transcription result: ' + JSON.stringify(result, null, 2));
                
                if (result.success) {
                    // Show transcription result
                    transcriptionText.textContent = result.transcription;
                    transcriptionResult.style.display = 'block';
                    
                    aiStatus.textContent = 'Transcription completed!';
                    addLog('üî• SUCCESS: Transcription completed successfully!');
                } else {
                    throw new Error(result.error || 'Unknown error');
                }
                
            } catch (error) {
                addLog('üî• Transcription error: ' + error.message);
                aiStatus.textContent = 'Transcription failed';
            } finally {
                // Reset UI
                aiBtn.className = 'record-btn';
                aiBtnText.textContent = 'Start Recording';
                aiMicIcon.textContent = 'üé§';
                aiBtn.disabled = false;
                recordingTimer.style.display = 'none';
            }
        }
    </script>
</body>
</html> 
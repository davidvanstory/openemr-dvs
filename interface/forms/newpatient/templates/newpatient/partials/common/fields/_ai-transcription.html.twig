{# AI Transcription Section - Adjacent to Reason for Visit #}
<div class="col-sm">
    <fieldset class="ai-transcription-section">
        <legend class="text-primary">{{ "AI Voice Transcription"|xlt }}</legend>
        <div class="card bg-light border-primary">
            <div class="card-body text-center">
                <div class="mb-3">
                    <p class="card-text text-muted mb-3">{{ "Record your conversation and transcribe it directly to Reason for Visit"|xlt }}</p>
                    
                    {# Large AI Transcription Button #}
                    <button type="button" id="aiTranscriptionBtn" class="btn btn-primary btn-lg px-4 py-3 me-3">
                        <i class="fas fa-microphone fa-lg" id="aiMicIcon"></i>
                        <span id="aiBtnText" class="ms-2">{{ "Record & Transcribe"|xlt }}</span>
                    </button>
                    
                    {# Status Display #}
                    <div class="mt-3">
                        <span id="aiStatus" class="badge badge-secondary">{{ "Ready to record"|xlt }}</span>
                        <div id="recordingTimer" class="mt-2 d-none">
                            <span class="text-muted">{{ "Recording time"|xlt }}: </span>
                            <span id="timerDisplay" class="fw-bold text-danger">00:00</span>
                        </div>
                    </div>
                </div>
                
                {# Transcription Preview Area #}
                <div id="transcriptionPreview" class="mt-4 d-none">
                    <div class="card border-success">
                        <div class="card-header bg-success text-white">
                            <h6 class="mb-0">{{ "Voice Transcription Preview"|xlt }}</h6>
                        </div>
                        <div class="card-body">
                            <p id="transcriptionText" class="card-text text-start"></p>
                            <div class="mt-3">
                                <button type="button" id="addToReason" class="btn btn-success">
                                    <i class="fas fa-plus"></i> {{ "Add to Reason for Visit"|xlt }}
                                </button>
                                <button type="button" id="replaceReason" class="btn btn-warning ms-2">
                                    <i class="fas fa-refresh"></i> {{ "Replace Reason for Visit"|xlt }}
                                </button>
                                <button type="button" id="clearTranscription" class="btn btn-outline-danger ms-2">
                                    <i class="fas fa-trash"></i> {{ "Clear"|xlt }}
                                </button>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </fieldset>
</div>

{# AI Transcription JavaScript #}
<script>
document.addEventListener('DOMContentLoaded', function() {
    console.log('AI Voice Transcription system initializing...');
    
    // Voice Recording Variables
    let mediaRecorder;
    let audioChunks = [];
    let isRecording = false;
    let recordingStartTime;
    let timerInterval;
    let currentTranscription = '';
    
    // DOM Elements
    const aiBtn = document.getElementById('aiTranscriptionBtn');
    const aiStatus = document.getElementById('aiStatus');
    const aiBtnText = document.getElementById('aiBtnText');
    const aiMicIcon = document.getElementById('aiMicIcon');
    const recordingTimer = document.getElementById('recordingTimer');
    const timerDisplay = document.getElementById('timerDisplay');
    const transcriptionPreview = document.getElementById('transcriptionPreview');
    const transcriptionText = document.getElementById('transcriptionText');
    const addToReason = document.getElementById('addToReason');
    const replaceReason = document.getElementById('replaceReason');
    const clearTranscription = document.getElementById('clearTranscription');
    
    // Get the Reason for Visit textarea
    const reasonTextarea = document.getElementById('reason');
    
    // Event Listeners
    aiBtn.addEventListener('click', async function() {
        console.log('AI Transcription button clicked, isRecording:', isRecording);
        if (!isRecording) {
            await startRecording();
        } else {
            stopRecording();
        }
    });
    
    addToReason.addEventListener('click', function() {
        addTranscriptionToReason();
    });
    
    replaceReason.addEventListener('click', function() {
        replaceReasonWithTranscription();
    });
    
    clearTranscription.addEventListener('click', clearTranscriptionData);
    
    async function startRecording() {
        try {
            console.log('Starting voice recording...');
            const stream = await navigator.mediaDevices.getUserMedia({ 
                audio: {
                    echoCancellation: true,
                    noiseSuppression: true,
                    sampleRate: 44100
                } 
            });
            
            // Determine best audio format
            let mimeType = 'audio/wav';
            const supportedTypes = [
                'audio/wav',
                'audio/webm;codecs=opus',
                'audio/webm',
                'audio/mp4',
                'audio/ogg;codecs=opus'
            ];
            
            for (const type of supportedTypes) {
                if (MediaRecorder.isTypeSupported(type)) {
                    mimeType = type;
                    console.log('Using MIME type:', mimeType);
                    break;
                }
            }
            
            mediaRecorder = new MediaRecorder(stream, { mimeType: mimeType });
            audioChunks = [];
            
            mediaRecorder.ondataavailable = function(event) {
                console.log('Audio data available:', event.data.size, 'bytes');
                audioChunks.push(event.data);
            };
            
            mediaRecorder.onstop = async function() {
                console.log('Recording stopped, processing audio...');
                const audioBlob = new Blob(audioChunks, { type: mimeType });
                console.log('Audio blob created:', audioBlob.size, 'bytes, type:', audioBlob.type);
                await transcribeAudio(audioBlob);
                stream.getTracks().forEach(track => track.stop());
            };
            
            // Start recording
            mediaRecorder.start(1000);
            isRecording = true;
            recordingStartTime = Date.now();
            
            // Update UI for recording state
            aiBtn.className = 'btn btn-danger btn-lg px-4 py-3 pulse';
            aiBtnText.textContent = '{{ "Stop Recording"|xlt }}';
            aiMicIcon.className = 'fas fa-stop fa-lg';
            aiStatus.textContent = '{{ "Recording in progress..."|xlt }}';
            aiStatus.className = 'badge badge-danger';
            
            // Show and start timer
            recordingTimer.classList.remove('d-none');
            startRecordingTimer();
            
        } catch (error) {
            console.error('Error accessing microphone:', error);
            aiStatus.textContent = '{{ "Error: Could not access microphone"|xlt }}';
            aiStatus.className = 'badge badge-danger';
            
            // Alert user about microphone permission
            alert('{{ "Unable to access microphone. Please check your browser permissions and try again."|xlt }}');
        }
    }
    
    function stopRecording() {
        if (mediaRecorder && isRecording) {
            console.log('Stopping recording...');
            mediaRecorder.stop();
            isRecording = false;
            
            // Stop timer
            if (timerInterval) {
                clearInterval(timerInterval);
            }
            
            // Update UI for processing state
            aiBtn.className = 'btn btn-warning btn-lg px-4 py-3';
            aiBtnText.textContent = '{{ "Processing..."|xlt }}';
            aiMicIcon.className = 'fas fa-spinner fa-spin fa-lg';
            aiStatus.textContent = '{{ "Transcribing with OpenAI Whisper..."|xlt }}';
            aiStatus.className = 'badge badge-warning';
            aiBtn.disabled = true;
        }
    }
    
    function startRecordingTimer() {
        timerInterval = setInterval(function() {
            if (recordingStartTime) {
                const elapsed = Date.now() - recordingStartTime;
                const minutes = Math.floor(elapsed / 60000);
                const seconds = Math.floor((elapsed % 60000) / 1000);
                timerDisplay.textContent = 
                    (minutes < 10 ? '0' : '') + minutes + ':' + 
                    (seconds < 10 ? '0' : '') + seconds;
            }
        }, 1000);
    }
    
    async function transcribeAudio(audioBlob) {
        const formData = new FormData();
        
        // Create filename with proper extension
        let filename = 'voice-recording.wav';
        if (audioBlob.type.includes('webm')) {
            filename = 'voice-recording.webm';
        } else if (audioBlob.type.includes('mp4')) {
            filename = 'voice-recording.m4a';
        } else if (audioBlob.type.includes('ogg')) {
            filename = 'voice-recording.ogg';
        }
        
        console.log('Uploading audio file:', filename, 'Size:', audioBlob.size, 'Type:', audioBlob.type);
        
        formData.append('audio', audioBlob, filename);
        formData.append('csrf_token_form', document.querySelector('input[name="csrf_token_form"]').value);
        
        try {
            // Use the correct endpoint: whisper_simple.php
            const response = await fetch('{{ webroot }}/interface/forms/newpatient/whisper_simple.php', {
                method: 'POST',
                body: formData
            });
            
            console.log('Transcription response status:', response.status);
            
            if (!response.ok) {
                const errorText = await response.text();
                console.error('Transcription server error:', errorText);
                throw new Error(`Server error (${response.status}): ${errorText.substring(0, 100)}`);
            }
            
            const result = await response.json();
            console.log('Transcription result:', result);
            
            if (result.success) {
                currentTranscription = result.transcription;
                displayTranscription(result.transcription);
                aiStatus.textContent = '{{ "Transcription completed!"|xlt }}';
                aiStatus.className = 'badge badge-success';
                
                // Show success message
                console.log('Voice transcription successful:', result.transcription.substring(0, 100) + '...');
            } else {
                throw new Error(result.error || 'Unknown transcription error');
            }
            
        } catch (error) {
            console.error('Transcription error:', error);
            aiStatus.textContent = '{{ "Transcription failed"|xlt }}';
            aiStatus.className = 'badge badge-danger';
            
            // Show user-friendly error message
            alert('{{ "Transcription failed"|xlt }}: ' + error.message);
        } finally {
            // Reset button
            aiBtn.disabled = false;
            aiBtnText.textContent = '{{ "Record & Transcribe"|xlt }}';
            aiMicIcon.className = 'fas fa-microphone fa-lg';
            aiBtn.className = 'btn btn-primary btn-lg px-4 py-3';
            recordingTimer.classList.add('d-none');
        }
    }
    
    function displayTranscription(text) {
        transcriptionText.textContent = text;
        transcriptionPreview.classList.remove('d-none');
    }
    
    function addTranscriptionToReason() {
        if (!currentTranscription || !reasonTextarea) {
            console.error('No transcription or reason textarea not found');
            return;
        }
        
        const currentReason = reasonTextarea.value.trim();
        let newValue;
        
        if (currentReason) {
            // Add transcription to existing content with proper spacing
            newValue = currentReason + '\n\n' + currentTranscription;
        } else {
            // Replace empty field with transcription
            newValue = currentTranscription;
        }
        
        reasonTextarea.value = newValue;
        
        // Trigger change event so form validation works
        reasonTextarea.dispatchEvent(new Event('change', { bubbles: true }));
        
        // Focus the textarea and show user the change
        reasonTextarea.focus();
        reasonTextarea.scrollTop = reasonTextarea.scrollHeight;
        
        console.log('Added transcription to Reason for Visit field');
        aiStatus.textContent = '{{ "Added to Reason for Visit"|xlt }}';
        aiStatus.className = 'badge badge-info';
        
        // Auto-clear the preview after adding
        setTimeout(clearTranscriptionData, 2000);
    }
    
    function replaceReasonWithTranscription() {
        if (!currentTranscription || !reasonTextarea) {
            console.error('No transcription or reason textarea not found');
            return;
        }
        
        // Confirm replacement if there's existing content
        const currentReason = reasonTextarea.value.trim();
        if (currentReason && !confirm('{{ "This will replace the existing Reason for Visit. Continue?"|xlt }}')) {
            return;
        }
        
        reasonTextarea.value = currentTranscription;
        
        // Trigger change event so form validation works
        reasonTextarea.dispatchEvent(new Event('change', { bubbles: true }));
        
        // Focus the textarea
        reasonTextarea.focus();
        
        console.log('Replaced Reason for Visit with transcription');
        aiStatus.textContent = '{{ "Replaced Reason for Visit"|xlt }}';
        aiStatus.className = 'badge badge-info';
        
        // Auto-clear the preview after replacing
        setTimeout(clearTranscriptionData, 2000);
    }
    
    function clearTranscriptionData() {
        currentTranscription = '';
        transcriptionPreview.classList.add('d-none');
        transcriptionText.textContent = '';
        aiStatus.textContent = '{{ "Ready to record"|xlt }}';
        aiStatus.className = 'badge badge-secondary';
        
        console.log('Cleared transcription data');
    }
});
</script>

{# AI Transcription Styles #}
<style>
.ai-transcription-section {
    border: 2px solid #007bff;
    border-radius: 10px;
    background-color: #f8f9fa;
}

.pulse {
    animation: pulse 2s infinite;
}

@keyframes pulse {
    0% {
        box-shadow: 0 0 0 0 rgba(220, 53, 69, 0.7);
    }
    70% {
        box-shadow: 0 0 0 10px rgba(220, 53, 69, 0);
    }
    100% {
        box-shadow: 0 0 0 0 rgba(220, 53, 69, 0);
    }
}

#aiTranscriptionBtn {
    min-width: 220px;
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 1px;
}

#transcriptionPreview .card-text {
    white-space: pre-wrap;
    max-height: 200px;
    overflow-y: auto;
    text-align: left;
}

/* Ensure proper spacing between form sections */
.ai-transcription-section {
    margin-top: 1rem;
}
</style> 
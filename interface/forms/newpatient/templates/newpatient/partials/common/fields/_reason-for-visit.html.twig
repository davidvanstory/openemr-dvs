<div class="col-sm">
    <fieldset>
        <legend>{{ "Reason for Visit"|xlt }}</legend>
        <div class="form-row mx-3 h-100">
            <textarea name="reason" id="reason" class="form-control" cols="80" rows="4">{%
                    if viewmode
                        %}{{ encounter.reason|default("")|text }}{%
                    else
                        %}{{ globals.default_chief_complaint|default("")|text }}{%
                    endif
            %}</textarea>
            
            <!-- Voice Recording Button - Always show -->
            <div class="mt-2">
                <button type="button" id="voiceRecordBtn" class="btn btn-outline-primary btn-sm">
                    <i class="fas fa-microphone" id="micIcon"></i>
                    <span id="btnText">{{ "Record & Transcribe"|xlt }}</span>
                </button>
                <small id="voiceStatus" class="ml-2 text-muted">{{ "Click to start recording"|xlt }}</small>
            </div>
        </div>
    </fieldset>
</div>

<!-- Voice Recording Script - Always include -->
<script>
document.addEventListener('DOMContentLoaded', function() {
    let mediaRecorder;
    let audioChunks = [];
    let isRecording = false;
    
    const btn = document.getElementById('voiceRecordBtn');
    const status = document.getElementById('voiceStatus');
    const btnText = document.getElementById('btnText');
    const micIcon = document.getElementById('micIcon');
    const reasonField = document.getElementById('reason');
    
    btn.addEventListener('click', async function() {
        if (!isRecording) {
            await startRecording();
        } else {
            stopRecording();
        }
    });
    
    async function startRecording() {
        try {
            console.log('Starting voice recording...');
            const stream = await navigator.mediaDevices.getUserMedia({ 
                audio: {
                    echoCancellation: true,
                    noiseSuppression: true,
                    sampleRate: 44100
                } 
            });
            
            // Try different mime types in order of preference
            let mimeType = 'audio/wav';
            const supportedTypes = [
                'audio/wav',
                'audio/webm;codecs=opus',
                'audio/webm',
                'audio/mp4',
                'audio/ogg;codecs=opus'
            ];
            
            for (const type of supportedTypes) {
                if (MediaRecorder.isTypeSupported(type)) {
                    mimeType = type;
                    break;
                }
            }
            
            console.log('Using MIME type:', mimeType);
            mediaRecorder = new MediaRecorder(stream, { mimeType: mimeType });
            audioChunks = [];
            
            mediaRecorder.ondataavailable = function(event) {
                console.log('Audio data available:', event.data.size, 'bytes');
                audioChunks.push(event.data);
            };
            
            mediaRecorder.onstop = async function() {
                console.log('Recording stopped, processing audio...');
                const audioBlob = new Blob(audioChunks, { type: mimeType });
                console.log('Audio blob created:', audioBlob.size, 'bytes, type:', audioBlob.type);
                await transcribeAudio(audioBlob);
                stream.getTracks().forEach(track => track.stop());
            };
            
            mediaRecorder.start(1000); // Collect data every second
            isRecording = true;
            
            btn.className = 'btn btn-danger btn-sm';
            btnText.textContent = '{{ "Stop Recording"|xlt }}';
            micIcon.className = 'fas fa-stop';
            status.textContent = '{{ "Recording... Click to stop"|xlt }}';
            status.className = 'ml-2 text-info';
            
        } catch (error) {
            console.error('Error accessing microphone:', error);
            status.textContent = '{{ "Error: Could not access microphone"|xlt }}';
            status.className = 'ml-2 text-danger';
        }
    }
    
    function stopRecording() {
        if (mediaRecorder && isRecording) {
            console.log('Stopping recording...');
            mediaRecorder.stop();
            isRecording = false;
            
            btn.className = 'btn btn-outline-primary btn-sm';
            btnText.textContent = '{{ "Transcribing..."|xlt }}';
            micIcon.className = 'fas fa-spinner fa-spin';
            status.textContent = '{{ "Processing audio with Whisper..."|xlt }}';
            status.className = 'ml-2 text-warning';
            btn.disabled = true;
        }
    }
    
    async function transcribeAudio(audioBlob) {
        const formData = new FormData();
        
        // Create a filename with proper extension
        let filename = 'recording.wav';
        if (audioBlob.type.includes('webm')) {
            filename = 'recording.webm';
        } else if (audioBlob.type.includes('mp4')) {
            filename = 'recording.m4a';
        } else if (audioBlob.type.includes('ogg')) {
            filename = 'recording.ogg';
        }
        
        console.log('Uploading audio file:', filename, 'Size:', audioBlob.size, 'Type:', audioBlob.type);
        
        formData.append('audio', audioBlob, filename);
        formData.append('csrf_token_form', document.querySelector('input[name="csrf_token_form"]').value);
        
        try {
            const response = await fetch('{{ webroot }}/interface/forms/newpatient/whisper_simple.php', {
                method: 'POST',
                body: formData
            });
            
            console.log('Response status:', response.status);
            
            if (!response.ok) {
                const errorText = await response.text();
                console.error('Server error response:', errorText);
                throw new Error(`Server error (${response.status}): ${errorText.substring(0, 100)}`);
            }
            
            const result = await response.json();
            console.log('Transcription result:', result);
            
            if (result.success) {
                // Insert transcription into reason field
                if (reasonField.value.trim()) {
                    reasonField.value += '\n\n' + result.transcription;
                } else {
                    reasonField.value = result.transcription;
                }
                status.textContent = '{{ "Transcription completed!"|xlt }}';
                status.className = 'ml-2 text-success';
            } else {
                throw new Error(result.error || 'Unknown transcription error');
            }
            
        } catch (error) {
            console.error('Transcription error:', error);
            status.textContent = '{{ "Transcription failed: "|xlt }}' + error.message;
            status.className = 'ml-2 text-danger';
        } finally {
            // Reset button
            btn.disabled = false;
            btnText.textContent = '{{ "Record & Transcribe"|xlt }}';
            micIcon.className = 'fas fa-microphone';
            btn.className = 'btn btn-outline-primary btn-sm';
        }
    }
});
</script>
